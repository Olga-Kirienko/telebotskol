import json
import os
import asyncio
import sys
import re
import random
import numpy as np
import librosa
import torch
import torchaudio
from typing import Dict, List, Tuple, Any
from gtts import gTTS
import aiofiles
from openai import AsyncOpenAI
import tempfile
from aiogram import types # –û—Å—Ç–∞–≤–ª—è–µ–º types, —Ç–∞–∫ –∫–∞–∫ –æ–Ω –Ω—É–∂–µ–Ω –¥–ª—è handle_voice_message
from aiogram.types import FSInputFile # –î–æ–±–∞–≤–ª—è–µ–º –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å —Ñ–∞–π–ª–∞–º–∏, –µ—Å–ª–∏ –ø–æ—Ç—Ä–µ–±—É–µ—Ç—Å—è –≤ –¥—Ä—É–≥–∏—Ö —Ñ—É–Ω–∫—Ü–∏—è—Ö
from transformers import Wav2Vec2Processor, Wav2Vec2ForCTC, Wav2Vec2FeatureExtractor, Wav2Vec2CTCTokenizer
from difflib import SequenceMatcher
import subprocess
from datetime import datetime # –î–æ–±–∞–≤–ª—è–µ–º datetime –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –∏–º–µ–Ω —Ñ–∞–π–ª–æ–≤

# --- –£—Å—Ç–∞–Ω–æ–≤–∫–∞ –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π –æ–∫—Ä—É–∂–µ–Ω–∏—è –¥–ª—è eSpeak NG (–µ—Å–ª–∏ —Ç—Ä–µ–±—É–µ—Ç—Å—è) ---
# –£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ eSpeak NG —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω –∏ –ø—É—Ç—å –∫ –µ–≥–æ –∏—Å–ø–æ–ª–Ω—è–µ–º–æ–º—É —Ñ–∞–π–ª—É –∫–æ—Ä—Ä–µ–∫—Ç–µ–Ω.
# –ü—Ä–∏–º–µ—Ä: C:\Program Files\eSpeak NG
os.environ['PATH'] += r';C:\Program Files\eSpeak NG'

# --- –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–µ–π –æ–¥–∏–Ω —Ä–∞–∑ –ø—Ä–∏ —Å—Ç–∞—Ä—Ç–µ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è ---
# –≠—Ç–∏ –º–æ–¥–µ–ª–∏ –∏—Å–ø–æ–ª—å–∑—É—é—Ç—Å—è –¥–ª—è —Ñ–æ–Ω–µ—Ç–∏—á–µ—Å–∫–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞ Wav2Vec2
feature_extractor = Wav2Vec2FeatureExtractor.from_pretrained("facebook/wav2vec2-lv-60-espeak-cv-ft")
tokenizer = Wav2Vec2CTCTokenizer.from_pretrained("facebook/wav2vec2-lv-60-espeak-cv-ft")
processor = Wav2Vec2Processor(feature_extractor=feature_extractor, tokenizer=tokenizer)
model = Wav2Vec2ForCTC.from_pretrained("facebook/wav2vec2-lv-60-espeak-cv-ft")

sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
from config import DATA_PATH, AUDIO_PATH, OPENAI_API_KEY

# –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å OpenAI API
OPENAI_AVAILABLE = bool(OPENAI_API_KEY)
if OPENAI_AVAILABLE:
    try:
        import openai
    except ImportError:
        OPENAI_AVAILABLE = False
        OPENAI_API_KEY = None

# --- –í—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏ –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å –¥–∞–Ω–Ω—ã–º–∏ –∏ –∞—É–¥–∏–æ ---
async def load_json_data(filename: str) -> Dict:
    """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ –∏–∑ JSON —Ñ–∞–π–ª–∞."""
    file_path = os.path.join(DATA_PATH, filename)
    try:
        async with aiofiles.open(file_path, 'r', encoding='utf-8') as file:
            content = await file.read()
            return json.loads(content)
    except FileNotFoundError:
        print(f"–§–∞–π–ª {filename} –Ω–µ –Ω–∞–π–¥–µ–Ω")
        return {}
    except json.JSONDecodeError:
        print(f"–û—à–∏–±–∫–∞ –¥–µ–∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏—è JSON –≤ —Ñ–∞–π–ª–µ {filename}")
        return {}


# –°–ª–æ–≤–∞—Ä—å –¥–ª—è –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏—è –ø—É—Ç–µ–π –∫ MP3 —Ñ–∞–π–ª–∞–º
# –ö–ª—é—á: (filename_prefix, lang, slow_mode) -> –ø—É—Ç—å_–∫_—Ñ–∞–π–ª—É
_mp3_cache = {}


async def generate_audio(text: str, filename_prefix: str, lang: str = 'en', slow_mode: bool = False) -> str:
    """
    –ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –∞—É–¥–∏–æ—Ñ–∞–π–ª –∏–∑ —Ç–µ–∫—Å—Ç–∞ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º gTTS.
    –ö—ç—à–∏—Ä—É–µ—Ç MP3 —Ñ–∞–π–ª—ã –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ç–µ–∫—Å—Ç–∞, —è–∑—ã–∫–∞ –∏ —Ä–µ–∂–∏–º–∞ —Å–∫–æ—Ä–æ—Å—Ç–∏.
    :param text: –¢–µ–∫—Å—Ç –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏.
    :param filename_prefix: –ë–∞–∑–æ–≤–æ–µ –∏–º—è —Ñ–∞–π–ª–∞ (–Ω–∞–ø—Ä–∏–º–µ—Ä, "apple" –∏–∑ JSON).
    :param lang: –Ø–∑—ã–∫.
    :param slow_mode: True –¥–ª—è –∑–∞–º–µ–¥–ª–µ–Ω–Ω–æ–π —Ä–µ—á–∏, False –¥–ª—è –æ–±—ã—á–Ω–æ–π.
    :return: –ü—É—Ç—å –∫ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ–º—É –∏–ª–∏ –∫—ç—à–∏—Ä–æ–≤–∞–Ω–Ω–æ–º—É MP3 —Ñ–∞–π–ª—É.
    """
    # –°–æ–∑–¥–∞—ë–º —É–Ω–∏–∫–∞–ª—å–Ω—ã–π —Å—É—Ñ—Ñ–∏–∫—Å –¥–ª—è —Ñ–∞–π–ª–∞, —á—Ç–æ–±—ã —É—á–∏—Ç—ã–≤–∞—Ç—å slow_mode
    speed_suffix = "_slow" if slow_mode else ""
    # –°–æ–∑–¥–∞—ë–º –¥–µ—Ç–µ—Ä–º–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ –∏–º—è —Ñ–∞–π–ª–∞, –∫–æ—Ç–æ—Ä–æ–µ –±—É–¥–µ—Ç —É–Ω–∏–∫–∞–ª—å–Ω–æ –¥–ª—è —Ç–µ–∫—Å—Ç–∞, —è–∑—ã–∫–∞ –∏ —Å–∫–æ—Ä–æ—Å—Ç–∏
    # –ò—Å–ø–æ–ª—å–∑—É–µ–º –∫–æ–º–±–∏–Ω–∞—Ü–∏—é filename_prefix –∏ —Ö—ç—à–∞ —Ç–µ–∫—Å—Ç–∞ –¥–ª—è –Ω–∞–¥—ë–∂–Ω–æ–≥–æ –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏—è,
    # –∏–∑–±–µ–≥–∞—è —Å–ª–∏—à–∫–æ–º –¥–ª–∏–Ω–Ω—ã—Ö –∏–º—ë–Ω —Ñ–∞–π–ª–æ–≤ –∏ —Å–æ—Ö—Ä–∞–Ω—è—è —á–∏—Ç–∞–µ–º–æ—Å—Ç—å.
    # –≠—Ç–æ –ø–æ–∑–≤–æ–ª—è–µ—Ç –∫—ç—à–∏—Ä–æ–≤–∞—Ç—å "Apple" –∏ "Apple_slow" –∫–∞–∫ —Ä–∞–∑–Ω—ã–µ —Ñ–∞–π–ª—ã.
    import hashlib # –í—Ä–µ–º–µ–Ω–Ω—ã–π –∏–º–ø–æ—Ä—Ç –¥–ª—è —Ö—ç—à–∞, –µ—Å–ª–∏ –æ–Ω –Ω—É–∂–µ–Ω —Ç–æ–ª—å–∫–æ –∑–¥–µ—Å—å
    text_hash = hashlib.md5(f"{text}-{lang}-{slow_mode}".encode('utf-8')).hexdigest()[:8] # –°–æ–∫—Ä–∞—â–∞–µ–º —Ö—ç—à

    # –ò—Å–ø–æ–ª—å–∑—É–µ–º clean_prefix, —á—Ç–æ–±—ã –∏–º—è —Ñ–∞–π–ª–∞ –±—ã–ª–æ –≤–∞–ª–∏–¥–Ω—ã–º –∏ –∫–æ—Ä–æ—Ç–∫–∏–º
    clean_prefix = re.sub(r'[^a-zA-Z0-9_]', '', filename_prefix).lower()
    if len(clean_prefix) > 20: # –û–±—Ä–µ–∑–∞–µ–º, —á—Ç–æ–±—ã –Ω–µ –±—ã–ª–æ —Å–ª–∏—à–∫–æ–º –¥–ª–∏–Ω–Ω—ã—Ö –ø—Ä–µ—Ñ–∏–∫—Å–æ–≤
        clean_prefix = clean_prefix[:20]

    final_filename = f"{clean_prefix}{speed_suffix}_{text_hash}.mp3"
    audio_file_path = os.path.join(AUDIO_PATH, final_filename)

    # –ö–ª—é—á –¥–ª—è –∫—ç—à–∞ –≤ –ø–∞–º—è—Ç–∏, —á—Ç–æ–±—ã –±—ã—Å—Ç—Ä–æ –Ω–∞–π—Ç–∏ —Ñ–∞–π–ª, –µ—Å–ª–∏ –æ–Ω —É–∂–µ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω
    cache_key = (text, lang, slow_mode)

    # 1. –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫—ç—à –≤ –ø–∞–º—è—Ç–∏
    if cache_key in _mp3_cache:
        cached_path = _mp3_cache[cache_key]
        if os.path.exists(cached_path):
            print(f"–ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –∫—ç—à–∏—Ä–æ–≤–∞–Ω–Ω—ã–π MP3 —Ñ–∞–π–ª –∏–∑ –ø–∞–º—è—Ç–∏: {cached_path}")
            return cached_path
        else:
            # –ï—Å–ª–∏ —Ñ–∞–π–ª —É–¥–∞–ª—ë–Ω —Å –¥–∏—Å–∫–∞, –Ω–æ —Å—Å—ã–ª–∫–∞ –≤ –∫—ç—à–µ –æ—Å—Ç–∞–ª–∞—Å—å, —É–¥–∞–ª—è–µ–º –µ—ë
            del _mp3_cache[cache_key]
            print(f"–ö—ç—à–∏—Ä–æ–≤–∞–Ω–Ω—ã–π MP3 —Ñ–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω –Ω–∞ –¥–∏—Å–∫–µ, –ø–µ—Ä–µ–≥–µ–Ω–µ—Ä–∞—Ü–∏—è.")

    # 2. –ï—Å–ª–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ –≤ –∫—ç—à–µ, –ø—Ä–æ–≤–µ—Ä—è–µ–º —Ñ–∞–π–ª –Ω–∞ –¥–∏—Å–∫–µ
    if os.path.exists(audio_file_path):
        print(f"–ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–π MP3 —Ñ–∞–π–ª –Ω–∞ –¥–∏—Å–∫–µ: {audio_file_path}")
        _mp3_cache[cache_key] = audio_file_path # –î–æ–±–∞–≤–ª—è–µ–º –≤ –∫—ç—à –≤ –ø–∞–º—è—Ç–∏
        return audio_file_path

    # 3. –ï—Å–ª–∏ —Ñ–∞–π–ª–∞ –Ω–µ—Ç, –≥–µ–Ω–µ—Ä–∏—Ä—É–µ–º –µ–≥–æ
    try:
        loop = asyncio.get_event_loop()
        await loop.run_in_executor(
            None,
            lambda: gTTS(text=text, lang=lang, slow=slow_mode).save(audio_file_path)
        )
        print(f"MP3 –∞—É–¥–∏–æ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–æ: {audio_file_path}")
        _mp3_cache[cache_key] = audio_file_path # –î–æ–±–∞–≤–ª—è–µ–º –≤ –∫—ç—à –≤ –ø–∞–º—è—Ç–∏
        return audio_file_path
    except Exception as e:
        print(f"–û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ MP3 –∞—É–¥–∏–æ: {e}")
        # –í —Å–ª—É—á–∞–µ –æ—à–∏–±–∫–∏, —É–¥–∞–ª—è–µ–º –Ω–µ–¥–æ–¥–µ–ª–∞–Ω–Ω—ã–π —Ñ–∞–π–ª, –µ—Å–ª–∏ –æ–Ω –µ—Å—Ç—å
        if os.path.exists(audio_file_path):
            os.remove(audio_file_path)
        return None
DATA_DIR = "data"
os.makedirs(DATA_DIR, exist_ok=True) # –°–æ–∑–¥–∞–µ–º –ø–∞–ø–∫—É, –µ—Å–ª–∏ –µ–µ –Ω–µ—Ç

PROGRESS_FILE = os.path.join(DATA_DIR, "user_progress.json")
class UserProgress:
    """–£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –ø—Ä–æ–≥—Ä–µ—Å—Å–æ–º –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è —Å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ–º –Ω–∞ –¥–∏—Å–∫."""

    def __init__(self):
        self.users_progress = {}
        self._load_progress() # –ó–∞–≥—Ä—É–∂–∞–µ–º –ø—Ä–æ–≥—Ä–µ—Å—Å –ø—Ä–∏ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏

    def _load_progress(self):
        """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –ø—Ä–æ–≥—Ä–µ—Å—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π –∏–∑ —Ñ–∞–π–ª–∞."""
        if os.path.exists(PROGRESS_FILE):
            try:
                with open(PROGRESS_FILE, 'r', encoding='utf-8') as f:
                    # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –∫–ª—é—á–∏ user_id –∏–∑ —Å—Ç—Ä–æ–∫ –≤ int, —Ç.–∫. JSON —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç –∏—Ö –∫–∞–∫ —Å—Ç—Ä–æ–∫–∏
                    loaded_data = json.load(f)
                    self.users_progress = {int(k): v for k, v in loaded_data.items()}
                print(f"–ü—Ä–æ–≥—Ä–µ—Å—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π –∑–∞–≥—Ä—É–∂–µ–Ω –∏–∑ {PROGRESS_FILE}")
            except (json.JSONDecodeError, ValueError) as e:
                print(f"–û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è —Ñ–∞–π–ª–∞ –ø—Ä–æ–≥—Ä–µ—Å—Å–∞ {PROGRESS_FILE}: {e}. –ù–∞—á–∏–Ω–∞–µ–º —Å —á–∏—Å—Ç–æ–≥–æ –ª–∏—Å—Ç–∞.")
                self.users_progress = {}
        else:
            print(f"–§–∞–π–ª –ø—Ä–æ–≥—Ä–µ—Å—Å–∞ {PROGRESS_FILE} –Ω–µ –Ω–∞–π–¥–µ–Ω. –ù–∞—á–∏–Ω–∞–µ–º —Å —á–∏—Å—Ç–æ–≥–æ –ª–∏—Å—Ç–∞.")

    def _save_progress(self):
        """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç –ø—Ä–æ–≥—Ä–µ—Å—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π –≤ —Ñ–∞–π–ª."""
        try:
            with open(PROGRESS_FILE, 'w', encoding='utf-8') as f:
                json.dump(self.users_progress, f, indent=4, ensure_ascii=False)
            # print(f"–ü—Ä–æ–≥—Ä–µ—Å—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π —Å–æ—Ö—Ä–∞–Ω–µ–Ω –≤ {PROGRESS_FILE}") # –ú–æ–∂–Ω–æ —Ä–∞—Å–∫–æ–º–º–µ–Ω—Ç–∏—Ä–æ–≤–∞—Ç—å –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏
        except IOError as e:
            print(f"–û—à–∏–±–∫–∞ –∑–∞–ø–∏—Å–∏ —Ñ–∞–π–ª–∞ –ø—Ä–æ–≥—Ä–µ—Å—Å–∞ {PROGRESS_FILE}: {e}")

    def get_progress(self, user_id: int) -> Dict:
        """–ü–æ–ª—É—á–∏—Ç—å –ø—Ä–æ–≥—Ä–µ—Å—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –∏–ª–∏ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –µ–≥–æ."""
        # –£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ —ç—Ç–∏ –ø–æ–ª—è –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É—é—Ç—Å—è –ø—Ä–∏ –ø–µ—Ä–≤–æ–º –ø–æ–ª—É—á–µ–Ω–∏–∏ –ø—Ä–æ–≥—Ä–µ—Å—Å–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
        # –î–æ–±–∞–≤–ª—è–µ–º current_pronunciation_data –∏ —É–¥–∞–ª—è–µ–º current_pronunciation_text,
        # —Ç–∞–∫ –∫–∞–∫ current_pronunciation_data –±—É–¥–µ—Ç –µ–≥–æ –∑–∞–º–µ–Ω–æ–π.
        return self.users_progress.get(user_id, {
            'current_block': 'terms',
            'current_item': 0,
            'completed_items': [],
            # 'current_pronunciation_text': None,  # –ú–æ–∂–Ω–æ —É–¥–∞–ª–∏—Ç—å, –µ—Å–ª–∏ –ø–µ—Ä–µ—Ö–æ–¥–∏–º –Ω–∞ current_pronunciation_data
            'current_pronunciation_slow_mode': False,
            'current_pronunciation_data': None,  # <--- –ù–û–í–û–ï –ü–û–õ–ï: –±—É–¥–µ—Ç —Ö—Ä–∞–Ω–∏—Ç—å –≤—Å—é –∏–Ω—Ñ—É –æ —Ñ—Ä–∞–∑–µ
        })

    def update_progress(self, user_id: int, **kwargs: Any):
        """–û–±–Ω–æ–≤–∏—Ç—å –ø—Ä–æ–≥—Ä–µ—Å—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –∏ —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å."""
        if user_id not in self.users_progress:
            self.users_progress[user_id] = self.get_progress(user_id)
        self.users_progress[user_id].update(kwargs)
        self._save_progress() # –°–æ—Ö—Ä–∞–Ω—è–µ–º –ø–æ—Å–ª–µ –∫–∞–∂–¥–æ–≥–æ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è

    def reset_progress(self, user_id: int):
        """–°–±—Ä–æ—Å–∏—Ç—å –ø—Ä–æ–≥—Ä–µ—Å—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –∏ —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å."""
        self.users_progress[user_id] = self.get_progress(user_id)
        self._save_progress() # –°–æ—Ö—Ä–∞–Ω—è–µ–º –ø–æ—Å–ª–µ —Å–±—Ä–æ—Å–∞


# --- –§—É–Ω–∫—Ü–∏–∏ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –ø—Ä–æ–∏–∑–Ω–æ—à–µ–Ω–∏—è ---

async def convert_ogg_to_wav(input_path: str, output_path: str):
    """–ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ—Ç OGG –∞—É–¥–∏–æ—Ñ–∞–π–ª –≤ WAV."""
    try:
        waveform, sample_rate = torchaudio.load(input_path)
        if waveform.shape[0] > 1:
            waveform = torch.mean(waveform, dim=0, keepdim=True)  # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º —Å—Ç–µ—Ä–µ–æ –≤ –º–æ–Ω–æ
        if sample_rate != 16000:
            resampler = torchaudio.transforms.Resample(orig_freq=sample_rate, new_freq=16000)
            waveform = resampler(waveform)
        torchaudio.save(output_path, waveform, 16000, format="wav")
        return True
    except Exception as e:
        print(f"–û—à–∏–±–∫–∞ –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏–∏ ogg ‚Üí wav: {e}")
        return False


# –°–ø–∏—Å–æ–∫ –¥–∏–∞–∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏—Ö –∑–Ω–∞–∫–æ–≤ IPA –¥–ª—è —É–¥–∞–ª–µ–Ω–∏—è/–Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–∏
DIACRITICS = [
    'Àê', 'Àë', 'Àà', 'Àå', ' ∞', ' ∑', ' ≤',
    '\u0325', '\u032C', '\u0303', '\u0329', '\u0361', 'Àû'
]

# –ì—Ä—É–ø–ø—ã –ø–æ—Ö–æ–∂–∏—Ö —Ñ–æ–Ω–µ–º –¥–ª—è –±–æ–ª–µ–µ —Ç–æ—á–Ω–æ–≥–æ —Å—Ä–∞–≤–Ω–µ–Ω–∏—è
similar_groups = [
    ['i', '…™', 'iÀê'],
    ['e', '…õ', 'eÀê'],
    ['√¶', 'a', ' å'],
    ['o', '…î', 'oÀê', ' ä'],
    ['u', 'uÀê', ' ä'],
    ['…ö', '…ôr', '…úr', '…úÀê'],
    ['Œ∏', 'f'],
    ['√∞', 'v'],
    ['s', 'z'],
    [' É', ' í'],
    ['t', 'd'],
    ['k', 'g'],
    ['p', 'b'],
    ['r', '…π', '…ª'],
    ['l', '…´'],
]


def normalize_phonemes(phonemes: str) -> str:
    """–ù–æ—Ä–º–∞–ª–∏–∑—É–µ—Ç —Ñ–æ–Ω–µ–º—ã, —É–¥–∞–ª—è—è –¥–∏–∞–∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏–µ –∑–Ω–∞–∫–∏ –∏ –ø—Ä–µ–æ–±—Ä–∞–∑—É—è —Å—Ö–æ–∂–∏–µ —Ñ–æ–Ω–µ–º—ã."""
    s = phonemes.strip()
    for d in DIACRITICS:
        esc = re.escape(d)
        s = re.sub(rf'([^\s])\s*{esc}', r'\1', s)  # –£–¥–∞–ª—è–µ–º –¥–∏–∞–∫—Ä–∏—Ç–∏–∫—É, –µ—Å–ª–∏ –æ–Ω–∞ —Å–ª–µ–¥—É–µ—Ç –∑–∞ —Ñ–æ–Ω–µ–º–æ–π –±–µ–∑ –ø—Ä–æ–±–µ–ª–∞
    s = re.sub(r'[ÀàÀå`¬¥ º\']', '', s)  # –£–¥–∞–ª—è–µ–º –∑–Ω–∞–∫–∏ —É–¥–∞—Ä–µ–Ω–∏—è/–∞–ø–æ—Å—Ç—Ä–æ—Ñ—ã

    # –ö–∞—Ä—Ç–∞ –¥–ª—è —É–ø—Ä–æ—â–µ–Ω–∏—è —Ñ–æ–Ω–µ–º
    phoneme_mapping = {
        '…úÀê': '…ö', '…ô ä': 'o ä', '…õ': 'e', '…îÀê': '…ëÀê', '…™': 'i', ' å': ' å',
        'a…™': 'a…™', '√¶': '√¶', '√∞': '√∞', 'Œ∏': 'Œ∏', '≈ã': '≈ã', ' É': ' É',
        ' í': ' í', 't É': 't É', 'd í': 'd í', 'j': 'j', 'w': 'w', 'r': '…π',
        'l': 'l',
    }

    for old, new in phoneme_mapping.items():
        s = s.replace(old, new)

    s = ''.join(s.split()).lower()  # –£–¥–∞–ª—è–µ–º –≤—Å–µ –ø—Ä–æ–±–µ–ª—ã –∏ –ø—Ä–∏–≤–æ–¥–∏–º –∫ –Ω–∏–∂–Ω–µ–º—É —Ä–µ–≥–∏—Å—Ç—Ä—É
    return s.strip()


def get_phonemes_from_espeak(text: str) -> str:
    """–ü–æ–ª—É—á–∞–µ—Ç —Ñ–æ–Ω–µ–º—ã (IPA) –¥–ª—è —Ç–µ–∫—Å—Ç–∞ —Å –ø–æ–º–æ—â—å—é eSpeak NG."""
    try:
        # –£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ espeak-ng.exe –Ω–∞—Ö–æ–¥–∏—Ç—Å—è –≤ PATH –∏–ª–∏ —É–∫–∞–∂–∏—Ç–µ –ø–æ–ª–Ω—ã–π –ø—É—Ç—å
        espeak_path = os.path.join(os.environ.get('ESPEAK_NG_PATH', r'C:\Program Files\eSpeak NG'), 'espeak-ng.exe')
        if not os.path.exists(espeak_path):
            raise FileNotFoundError(
                f"espeak-ng.exe –Ω–µ –Ω–∞–π–¥–µ–Ω –ø–æ –ø—É—Ç–∏: {espeak_path}. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ —É—Å—Ç–∞–Ω–æ–≤–∫—É eSpeak NG –∏–ª–∏ –ø–µ—Ä–µ–º–µ–Ω–Ω—É—é –æ–∫—Ä—É–∂–µ–Ω–∏—è ESPEAK_NG_PATH.")

        result = subprocess.run(
            [espeak_path, '-q', '--ipa', text],
            capture_output=True,
            text=True,
            encoding='utf-8',
            check=True
        )
        return result.stdout.strip()
    except FileNotFoundError as e:
        print(f"–û—à–∏–±–∫–∞: {e}")
        return ""
    except subprocess.CalledProcessError as e:
        print(f"–û—à–∏–±–∫–∞ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è espeak-ng (–∫–æ–¥: {e.returncode}): {e.stderr}")
        return ""
    except Exception as e:
        print(f"–û–±—â–∞—è –æ—à–∏–±–∫–∞ –ø—Ä–∏ –≤—ã–∑–æ–≤–µ espeak-ng: {e}")
        return ""


def text_to_phonemes_simplified(text: str) -> str:
    """–ü—Ä–µ–æ–±—Ä–∞–∑—É–µ—Ç —Ç–µ–∫—Å—Ç –≤ —É–ø—Ä–æ—â–µ–Ω–Ω—ã–µ —Ñ–æ–Ω–µ–º—ã."""
    ipa_output = get_phonemes_from_espeak(text)
    normalized = normalize_phonemes(ipa_output)
    return normalized


async def audio_to_phonemes(audio_path: str) -> str:
    """–¢—Ä–∞–Ω—Å–∫—Ä–∏–±–∏—Ä—É–µ—Ç –∞—É–¥–∏–æ –≤ —Ñ–æ–Ω–µ–º—ã —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º Wav2Vec2 –º–æ–¥–µ–ª–∏."""
    try:
        # torchaudio.load() –º–æ–∂–µ—Ç –±—ã—Ç—å –±–æ–ª–µ–µ —É–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—ã–º –¥–ª—è —Ä–∞–∑–Ω—ã—Ö —Ñ–æ—Ä–º–∞—Ç–æ–≤
        waveform, sr = torchaudio.load(audio_path)

        if waveform.shape[0] > 1:
            waveform = torch.mean(waveform, dim=0)  # –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è —Å—Ç–µ—Ä–µ–æ –≤ –º–æ–Ω–æ

        if sr != 16000:
            resampler = torchaudio.transforms.Resample(orig_freq=sr, new_freq=16000)
            waveform = resampler(waveform)

        # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –≥—Ä–æ–º–∫–æ—Å—Ç–∏ –¥–ª—è Wav2Vec2
        waveform = (waveform - waveform.mean()) / (waveform.std() + 1e-7)

        input_values = processor(waveform.numpy(), return_tensors="pt", sampling_rate=16000).input_values
        with torch.no_grad():
            logits = model(input_values).logits
        predicted_ids = torch.argmax(logits, dim=-1)
        transcription = processor.decode(predicted_ids[0])
        normalized = normalize_phonemes(transcription)
        return normalized
    except Exception as e:
        print(f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∞—É–¥–∏–æ –≤ —Ñ–æ–Ω–µ–º—ã: {e}")
        return ""


def advanced_phoneme_comparison(expected: str, user: str) -> float:
    """
    –°—Ä–∞–≤–Ω–∏–≤–∞–µ—Ç –¥–≤–µ —Å—Ç—Ä–æ–∫–∏ —Ñ–æ–Ω–µ–º, –∏—Å–ø–æ–ª—å–∑—É—è SequenceMatcher.ratio()
    –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –æ–±—â–µ–π —Ç–æ—á–Ω–æ—Å—Ç–∏.
    """
    if not expected and not user:
        return 100.0
    if not expected or not user:
        return 0.0  # –ï—Å–ª–∏ –æ–¥–Ω–∞ —Å—Ç—Ä–æ–∫–∞ –ø—É—Å—Ç–∞, –∞ –¥—Ä—É–≥–∞—è –Ω–µ—Ç

    matcher = SequenceMatcher(None, expected, user)
    return round(matcher.ratio() * 100, 1)


def _preprocess_text_for_phoneme_splitting(text: str) -> str:
    """
    –ü—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ —Ç–µ–∫—Å—Ç–∞ –¥–ª—è —Ä–∞–∑–¥–µ–ª–µ–Ω–∏—è –Ω–∞ —Å–ª–æ–≤–∞
    –¥–ª—è –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ–≥–æ –ø–æ–ª—É—á–µ–Ω–∏—è —Ñ–æ–Ω–µ–º.
    """
    text = re.sub(r"['‚Äô-]", " ", text)  # –ó–∞–º–µ–Ω—è–µ–º –∞–ø–æ—Å—Ç—Ä–æ—Ñ—ã –∏ –¥–µ—Ñ–∏—Å—ã –ø—Ä–æ–±–µ–ª–∞–º–∏
    text = re.sub(r'[^\w\s]', '', text)  # –£–¥–∞–ª—è–µ–º –∑–Ω–∞–∫–∏ –ø—Ä–µ–ø–∏–Ω–∞–Ω–∏—è
    text = re.sub(r'\s+', ' ', text).strip()  # –£–±–∏—Ä–∞–µ–º –ª–∏—à–Ω–∏–µ –ø—Ä–æ–±–µ–ª—ã
    return text.lower()


def analyze_word_errors(
        text_words: List[str],
        orig_phonemes: str,  # –≠—Ç–æ flat —Å—Ç—Ä–æ–∫–∞
        user_phonemes: str  # –≠—Ç–æ flat —Å—Ç—Ä–æ–∫–∞
) -> List[Dict]:
    """–ê–Ω–∞–ª–∏–∑ –æ—à–∏–±–æ–∫ –ø—Ä–æ–∏–∑–Ω–æ—à–µ–Ω–∏—è –ø–æ –æ—Ç–¥–µ–ª—å–Ω—ã–º —Å–ª–æ–≤–∞–º."""

    # –ï—Å–ª–∏ orig_phonemes –Ω–µ –±—ã–ª –ø–æ–ª—É—á–µ–Ω —Å –ø—Ä–æ–±–µ–ª–∞–º–∏ –º–µ–∂–¥—É —Å–ª–æ–≤–∞–º–∏,
    # –Ω–∞–º –Ω—É–∂–Ω–æ –ø–æ–ª—É—á–∏—Ç—å —Ñ–æ–Ω–µ–º–Ω–æ–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏–µ –∫–∞–∂–¥–æ–≥–æ —Å–ª–æ–≤–∞ –æ—Ç–¥–µ–ª—å–Ω–æ
    # –¥–ª—è –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ–≥–æ —Ä–∞–∑–¥–µ–ª–µ–Ω–∏—è –Ω–∞ –≥—Ä–∞–Ω–∏—Ü—ã —Å–ª–æ–≤.
    # orig_phonemes, –ø–µ—Ä–µ–¥–∞–Ω–Ω–∞—è —Å—é–¥–∞, —É–∂–µ —è–≤–ª—è–µ—Ç—Å—è "–ø–ª–æ—Å–∫–æ–π" —Å—Ç—Ä–æ–∫–æ–π –∏–∑ `text_to_phonemes_simplified`.
    # –ü–æ—ç—Ç–æ–º—É –¥–ª—è –ø–æ—Å–ª–æ–≤–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞ –Ω–∞–º –Ω—É–∂–Ω–æ —Å–Ω–æ–≤–∞ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å —Ñ–æ–Ω–µ–º—ã –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —Å–ª–æ–≤–∞.
    orig_words_phonemes_separated = [text_to_phonemes_simplified(word) for word in text_words]

    # –°–æ–∑–¥–∞–µ–º "–ø–ª–æ—Å–∫—É—é" –≤–µ—Ä—Å–∏—é —ç—Ç–∞–ª–æ–Ω–Ω—ã—Ö —Ñ–æ–Ω–µ–º, –Ω–æ —Ç–µ–ø–µ—Ä—å –≥–∞—Ä–∞–Ω—Ç–∏—Ä–æ–≤–∞–Ω–Ω–æ —Ä–∞–∑–±–∏—Ç—É—é –ø–æ —Å–ª–æ–≤–∞–º,
    # —á—Ç–æ–±—ã —Å–æ–ø–æ—Å—Ç–∞–≤–∏—Ç—å –≥—Ä–∞–Ω–∏—Ü—ã —Å–ª–æ–≤.
    orig_flat_with_word_boundaries = "".join(orig_words_phonemes_separated)
    user_flat = user_phonemes  # user_phonemes —É–∂–µ –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω—ã –∏ –±–µ–∑ –ø—Ä–æ–±–µ–ª–æ–≤

    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ–±—ã –¥–ª–∏–Ω—ã —Ñ–æ–Ω–µ–º —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–æ–≤–∞–ª–∏ –æ–∂–∏–¥–∞–µ–º—ã–º
    if not orig_flat_with_word_boundaries and not user_flat:  # –û–±–µ —Å—Ç—Ä–æ–∫–∏ –ø—É—Å—Ç—ã
        return []
    if not orig_flat_with_word_boundaries or not user_flat:  # –û–¥–Ω–∞ —Å—Ç—Ä–æ–∫–∞ –ø—É—Å—Ç–∞, –¥—Ä—É–≥–∞—è –Ω–µ—Ç
        # –í —ç—Ç–æ–º —Å–ª—É—á–∞–µ –ø–æ—Å–ª–æ–≤–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –º–æ–∂–µ—Ç –±—ã—Ç—å –Ω–µ–∏–Ω—Ñ–æ—Ä–º–∞—Ç–∏–≤–µ–Ω,
        # –Ω–æ –º—ã –¥–æ–ª–∂–Ω—ã —Ö–æ—Ç—è –±—ã —É–∫–∞–∑–∞—Ç—å, —á—Ç–æ —á—Ç–æ-—Ç–æ –Ω–µ —Ç–∞–∫.
        # –≠—Ç–æ –∫—Ä–∞–π–Ω–∏–π —Å–ª—É—á–∞–π, –∫–æ—Ç–æ—Ä—ã–π –æ–±—ã—á–Ω–æ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç—Å—è –Ω–∞ —É—Ä–æ–≤–Ω–µ overall_accuracy.
        # –î–ª—è –ø—Ä–æ—Å—Ç–æ—Ç—ã, –µ—Å–ª–∏ –µ—Å—Ç—å —Å–ª–æ–≤–∞ –≤ text_words, –≤–µ—Ä–Ω–µ–º –ø–æ –Ω–∏–º 0%
        return [{
            'word': word,
            'expected': text_to_phonemes_simplified(word),
            'detected': user_flat,  # detected_word_phonemes –Ω–µ –ø–æ–ª—É—á–∏—Ç—Å—è —Ç–æ—á–Ω–æ –≤—ã–¥–µ–ª–∏—Ç—å
            'accuracy': 0.0,
            'errors': ["–ó–Ω–∞—á–∏—Ç–µ–ª—å–Ω—ã–µ —Ä–∞—Å—Ö–æ–∂–¥–µ–Ω–∏—è —Å –æ–∂–∏–¥–∞–µ–º—ã–º –ø—Ä–æ–∏–∑–Ω–æ—à–µ–Ω–∏–µ–º –≤—Å–µ–≥–æ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è."]
        } for word in text_words]

    word_boundaries = []
    current_pos = 0
    for word_ph_separated in orig_words_phonemes_separated:
        start = current_pos
        end = start + len(word_ph_separated)
        word_boundaries.append((start, end))
        current_pos = end

    # –ò—Å–ø–æ–ª—å–∑—É–µ–º SequenceMatcher –¥–ª—è –æ–±—â–µ–≥–æ –≤—ã—Ä–∞–≤–Ω–∏–≤–∞–Ω–∏—è –¥–≤—É—Ö –ø–æ–ª–Ω—ã—Ö —Å—Ç—Ä–æ–∫ —Ñ–æ–Ω–µ–º
    matcher = SequenceMatcher(None, orig_flat_with_word_boundaries, user_flat)
    alignment = matcher.get_opcodes()

    results = []

    for idx, (start, end) in enumerate(word_boundaries):
        if idx >= len(text_words):
            break

        word = text_words[idx]
        expected_word_phonemes = orig_flat_with_word_boundaries[start:end]

        detected_word_phonemes = ''

        # –°–æ–±–∏—Ä–∞–µ–º —Ñ–æ–Ω–µ–º—ã, –ø—Ä–æ–∏–∑–Ω–µ—Å–µ–Ω–Ω—ã–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º, –¥–ª—è —Ç–µ–∫—É—â–µ–≥–æ —Å–ª–æ–≤–∞
        # –ò–¥–µ–º –ø–æ –æ–±—â–µ–º—É –≤—ã—Ä–∞–≤–Ω–∏–≤–∞–Ω–∏—é –∏ –∏–∑–≤–ª–µ–∫–∞–µ–º —Ç–µ —á–∞—Å—Ç–∏, –∫–æ—Ç–æ—Ä—ã–µ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—Ç —Ç–µ–∫—É—â–µ–º—É —Å–ª–æ–≤—É
        for tag, i1, i2, j1, j2 in alignment:
            # i1, i2 –æ—Ç–Ω–æ—Å—è—Ç—Å—è –∫ orig_flat_with_word_boundaries
            # j1, j2 –æ—Ç–Ω–æ—Å—è—Ç—Å—è –∫ user_flat

            # –ï—Å–ª–∏ –±–ª–æ–∫ –≤—ã—Ä–∞–≤–Ω–∏–≤–∞–Ω–∏—è –ø–æ–ª–Ω–æ—Å—Ç—å—é –¥–æ –Ω–∞—á–∞–ª–∞ —Ç–µ–∫—É—â–µ–≥–æ —Å–ª–æ–≤–∞
            if i2 <= start:
                continue
            # –ï—Å–ª–∏ –±–ª–æ–∫ –≤—ã—Ä–∞–≤–Ω–∏–≤–∞–Ω–∏—è –ø–æ–ª–Ω–æ—Å—Ç—å—é –ø–æ—Å–ª–µ –∫–æ–Ω—Ü–∞ —Ç–µ–∫—É—â–µ–≥–æ —Å–ª–æ–≤–∞
            if i1 >= end:
                break

            # –ù–∞—Ö–æ–¥–∏–º –ø–µ—Ä–µ—Å–µ—á–µ–Ω–∏–µ –±–ª–æ–∫–∞ –≤—ã—Ä–∞–≤–Ω–∏–≤–∞–Ω–∏—è —Å –≥—Ä–∞–Ω–∏—Ü–∞–º–∏ —Ç–µ–∫—É—â–µ–≥–æ —Å–ª–æ–≤–∞
            clip_start_orig = max(i1, start)
            clip_end_orig = min(i2, end)

            if clip_end_orig <= clip_start_orig:  # –ï—Å–ª–∏ –Ω–µ—Ç –ø–µ—Ä–µ—Å–µ—á–µ–Ω–∏—è –∏–ª–∏ –æ–Ω–æ –Ω—É–ª–µ–≤–æ–µ
                continue

            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º, –∫–∞–∫—É—é —á–∞—Å—Ç—å –∏–∑ user_flat –Ω—É–∂–Ω–æ –≤–∑—è—Ç—å
            # –≠—Ç–æ –ø—Ä–∏–±–ª–∏–∑–∏—Ç–µ–ª—å–Ω—ã–π —Ä–∞—Å—á–µ—Ç, –æ—Å–Ω–æ–≤–∞–Ω–Ω—ã–π –Ω–∞ –ø—Ä–æ–ø–æ—Ä—Ü–∏–∏
            # –ë–æ–ª–µ–µ —Ç–æ—á–Ω–æ–µ —Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏–µ —Ç—Ä–µ–±—É–µ—Ç –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏—è –Ω–æ–≤–æ–≥–æ SequenceMatcher –¥–ª—è –∫–∞–∂–¥–æ–π –ø–∞—Ä—ã —Å–ª–æ–≤–æ-–ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å

            # –ü—Ä–æ–ø–æ—Ä—Ü–∏—è —Ç–µ–∫—É—â–µ–≥–æ —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è/—Ä–∞–∑–ª–∏—á–∏—è –≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ –≤—Å–µ–≥–æ –±–ª–æ–∫–∞
            ratio_in_block = (clip_end_orig - clip_start_orig) / (i2 - i1) if (i2 - i1) > 0 else 0

            # –ß–∞—Å—Ç—å, –∫–æ—Ç–æ—Ä–∞—è –±—ã–ª–∞ –ø—Ä–æ–∏–∑–Ω–µ—Å–µ–Ω–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º –¥–ª—è —ç—Ç–æ–π —á–∞—Å—Ç–∏ –±–ª–æ–∫–∞
            detected_segment_length = int((j2 - j1) * ratio_in_block)

            # –ï—Å–ª–∏ tag - 'equal' –∏–ª–∏ 'replace', –±–µ—Ä–µ–º —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â—É—é —á–∞—Å—Ç—å –∏–∑ –ø—Ä–æ–∏–∑–Ω–µ—Å–µ–Ω–Ω—ã—Ö
            if tag in ('equal', 'replace'):
                # –î–æ–±–∞–≤–ª—è–µ–º —á–∞—Å—Ç—å, –∫–æ—Ç–æ—Ä–∞—è —Å–æ–≤–ø–∞–¥–∞–µ—Ç –∏–ª–∏ —è–≤–ª—è–µ—Ç—Å—è –∑–∞–º–µ–Ω–æ–π
                detected_word_phonemes += user_flat[j1: j1 + detected_segment_length]
            elif tag == 'insert' and (i1 >= start and i1 < end):
                # –ï—Å–ª–∏ —ç—Ç–æ "–≤—Å—Ç–∞–≤–∫–∞" –≤ –æ–∂–∏–¥–∞–µ–º–æ–º —Ç–µ–∫—Å—Ç–µ, –Ω–æ —Ñ–∞–∫—Ç–∏—á–µ—Å–∫–∏ –≤ –ø—Ä–æ–∏–∑–Ω–µ—Å–µ–Ω–Ω–æ–º, –∏ –æ–Ω–∞ –ø–æ–ø–∞–¥–∞–µ—Ç –≤ –≥—Ä–∞–Ω–∏—Ü—ã —Å–ª–æ–≤–∞
                detected_word_phonemes += user_flat[j1: j2]  # –í—Å—Ç–∞–≤–∫–∞ —Ü–µ–ª–∏–∫–æ–º

        # –¢–µ–ø–µ—Ä—å, –∫–æ–≥–¥–∞ —É –Ω–∞—Å –µ—Å—Ç—å –ø—Ä–µ–¥–ø–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω–æ –ø—Ä–æ–∏–∑–Ω–µ—Å–µ–Ω–Ω—ã–µ —Ñ–æ–Ω–µ–º—ã –¥–ª—è —Å–ª–æ–≤–∞, —Å—Ä–∞–≤–Ω–∏–≤–∞–µ–º –∏—Ö
        if not detected_word_phonemes and expected_word_phonemes:
            # –°–ª—É—á–∞–π, –∫–æ–≥–¥–∞ —Å–ª–æ–≤–æ –±—ã–ª–æ –ø–æ–ª–Ω–æ—Å—Ç—å—é –ø—Ä–æ–ø—É—â–µ–Ω–æ –∏–ª–∏ –Ω–µ —Ä–∞—Å–ø–æ–∑–Ω–∞–Ω–æ
            accuracy = 0.0
            errors = [f"–ü–æ–ª–Ω–æ—Å—Ç—å—é –ø—Ä–æ–ø—É—Å—Ç–∏–ª–∏ –∏–ª–∏ —Å–∏–ª—å–Ω–æ –∏—Å–∫–∞–∑–∏–ª–∏ –ø—Ä–æ–∏–∑–Ω–æ—à–µ–Ω–∏–µ."]
            highlighted_expected = [f"<b>{expected_word_phonemes}</b>"]
            highlighted_detected = ["-"]  # –û–±–æ–∑–Ω–∞—á–∞–µ–º –æ—Ç—Å—É—Ç—Å—Ç–≤–∏–µ
        elif not expected_word_phonemes and detected_word_phonemes:
            # –°–ª—É—á–∞–π, –∫–æ–≥–¥–∞ –≤ –æ–∂–∏–¥–∞–µ–º–æ–º —Å–ª–æ–≤–µ –Ω–µ—Ç —Ñ–æ–Ω–µ–º (—Ä–µ–¥–∫–æ, –Ω–æ –≤–æ–∑–º–æ–∂–Ω–æ), –∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å —á—Ç–æ-—Ç–æ –ø—Ä–æ–∏–∑–Ω–µ—Å
            accuracy = 0.0  # –ù–µ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É–µ—Ç –æ–∂–∏–¥–∞–µ–º–æ–º—É
            errors = [f"–õ–∏—à–Ω–µ–µ –ø—Ä–æ–∏–∑–Ω–æ—à–µ–Ω–∏–µ: '{detected_word_phonemes}'"]
            highlighted_expected = ["-"]
            highlighted_detected = [f"<b>{detected_word_phonemes}</b>"]
        elif not expected_word_phonemes and not detected_word_phonemes:
            accuracy = 100.0  # –û–±–∞ –ø—É—Å—Ç—ã - –∏–¥–µ–∞–ª—å–Ω–æ
            errors = []
            highlighted_expected = [""]
            highlighted_detected = [""]
        else:
            # –î–µ—Ç–∞–ª—å–Ω–æ–µ —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ –¥–ª—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ —Å–ª–æ–≤–∞
            matcher_word = SequenceMatcher(None, expected_word_phonemes, detected_word_phonemes)
            word_alignment = matcher_word.get_opcodes()

            highlighted_expected = []
            highlighted_detected = []
            errors = []

            for tag, i1, i2, j1, j2 in word_alignment:
                exp_chunk = expected_word_phonemes[i1:i2]
                det_chunk = detected_word_phonemes[j1:j2]

                if tag == 'equal':
                    highlighted_expected.append(exp_chunk)
                    highlighted_detected.append(det_chunk)
                elif tag == 'replace':
                    highlighted_expected.append(f"<b>{exp_chunk}</b>")
                    highlighted_detected.append(f"<b>{det_chunk}</b>")
                    errors.append(f"–ó–∞–º–µ–Ω–∏–ª–∏ '{exp_chunk}' –Ω–∞ '{det_chunk}'")
                elif tag == 'delete':
                    highlighted_expected.append(f"<b>{exp_chunk}</b>")
                    errors.append(f"–ü—Ä–æ–ø—É—Å—Ç–∏–ª–∏ '{exp_chunk}'")
                elif tag == 'insert':
                    highlighted_detected.append(f"<b>{det_chunk}</b>")
                    errors.append(f"–î–æ–±–∞–≤–∏–ª–∏ –ª–∏—à–Ω–µ–µ '{det_chunk}'")

            accuracy = matcher_word.ratio() * 100

        results.append({
            'word': word,
            'expected': ''.join(highlighted_expected),
            'detected': ''.join(highlighted_detected),
            'accuracy': accuracy,
            'errors': errors
        })

    return results


async def simple_pronunciation_check(
        target_text: str,
        user_audio_path: str,
        lower_threshold: float,
        upper_threshold: float
) -> Tuple[float, str, str]:
    """
    –í—ã–ø–æ–ª–Ω—è–µ—Ç –ø—Ä–æ–≤–µ—Ä–∫—É –ø—Ä–æ–∏–∑–Ω–æ—à–µ–Ω–∏—è –∞—É–¥–∏–æ—Ñ–∞–π–ª–∞.
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –æ–±—â—É—é —Ç–æ—á–Ω–æ—Å—Ç—å, –≤–µ—Ä–¥–∏–∫—Ç –∏ –¥–µ—Ç–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ (–µ—Å–ª–∏ —É–º–µ—Å—Ç–Ω–æ).
    """
    expected_phonemes = text_to_phonemes_simplified(target_text)
    user_phonemes = await audio_to_phonemes(user_audio_path)

    # –¢–µ–ø–µ—Ä—å overall_accuracy –±—É–¥–µ—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å SequenceMatcher.ratio() –¥–ª—è –≤—Å–µ–π —Å—Ç—Ä–æ–∫–∏
    overall_accuracy = advanced_phoneme_comparison(expected_phonemes, user_phonemes)

    verdict = ""
    analysis_text = ""

    print(f"–ò—Å–ø–æ–ª—å–∑—É–µ–º—ã–µ –ø–æ—Ä–æ–≥–∏: –ù–∏–∂–Ω–∏–π: {lower_threshold:.1f}%, –í–µ—Ä—Ö–Ω–∏–π: {upper_threshold:.1f}%")
    print(f"–û–∂–∏–¥–∞–µ–º—ã–µ —Ñ–æ–Ω–µ–º—ã: {expected_phonemes}")
    print(f"–§–æ–Ω–µ–º—ã –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è: {user_phonemes}")

    if overall_accuracy >= upper_threshold:
        verdict = "üéâ <b>–û—Ç–ª–∏—á–Ω–æ–µ –ø—Ä–æ–∏–∑–Ω–æ—à–µ–Ω–∏–µ!</b>"
        analysis_text = ""
    elif overall_accuracy >= lower_threshold:
        verdict = "üëç <b>–•–æ—Ä–æ—à–æ, –Ω–æ –º–æ–∂–Ω–æ –ª—É—á—à–µ!</b>"
        # –†–∞–∑–±–∏–≤–∞–µ–º –∏—Å—Ö–æ–¥–Ω—ã–π —Ç–µ–∫—Å—Ç –Ω–∞ —Å–ª–æ–≤–∞ –¥–ª—è –ø–æ—Å–ª–æ–≤–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞
        text_words_processed = _preprocess_text_for_phoneme_splitting(target_text).split()
        word_results = analyze_word_errors(text_words_processed, expected_phonemes, user_phonemes)

        analysis = ["\n\nüìù <b>–û–±–Ω–∞—Ä—É–∂–µ–Ω—ã —Å–ª–µ–¥—É—é—â–∏–µ –æ—à–∏–±–∫–∏ –ø—Ä–æ–∏–∑–Ω–æ—à–µ–Ω–∏—è:</b>"]
        for result in word_results:
            analysis.append(f"\n‚ñ∏ <b>{result['word'].upper()}</b> ({result['accuracy']:.1f}%)")
            analysis.append(f" ¬† üîπ –û–∂–∏–¥–∞–ª–æ—Å—å: /{result['expected']}/")
            analysis.append(f" ¬† üî∏ –ü—Ä–æ–∏–∑–Ω–µ—Å–µ–Ω–æ: /{result['detected']}/")
            if result['errors']:
                analysis.append(" ¬† üí° –ü–æ–¥—Ä–æ–±–Ω–µ–µ: ")
                for error_detail in result['errors']:
                    analysis.append(f" ¬† ¬† ‚Ä¢ {error_detail}")
        analysis_text = "\n".join(analysis)
    else:  # accuracy < lower_threshold
        verdict = "üëé <b>–¢—Ä–µ–±—É–µ—Ç—Å—è –±–æ–ª—å—à–µ –ø—Ä–∞–∫—Ç–∏–∫–∏!</b>"
        analysis_text = "\n\n<i>–ü–æ–ø—Ä–æ–±—É–π—Ç–µ —Å–æ—Å—Ä–µ–¥–æ—Ç–æ—á–∏—Ç—å—Å—è –Ω–∞ –æ—Å–Ω–æ–≤–Ω—ã—Ö –∑–≤—É–∫–∞—Ö. –ü—Ä–∞–∫—Ç–∏–∫—É–π—Ç–µ—Å—å –º–µ–¥–ª–µ–Ω–Ω–æ –∏ —á–µ—Ç–∫–æ.</i>"

    return overall_accuracy, verdict, analysis_text


# --- –§—É–Ω–∫—Ü–∏–∏ AI –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–∞ ---

async def get_teacher_response(question: str) -> str:
    """–ü–æ–ª—É—á–∞–µ—Ç –æ—Ç–≤–µ—Ç –æ—Ç AI —É—á–∏—Ç–µ–ª—è –ø–æ –≥—Ä–∞–º–º–∞—Ç–∏–∫–µ."""
    if not OPENAI_AVAILABLE:
        return await get_simple_teacher_response(question)
    try:
        system_prompt = """–¢—ã ‚Äî –ø–æ–º–æ—â–Ω–∏–∫ –≤ Telegram-–±–æ—Ç–µ –ø–æ –∏–∑—É—á–µ–Ω–∏—é –∞–Ω–≥–ª–∏–π—Å–∫–æ–≥–æ —è–∑—ã–∫–∞. 
–û—Ç–≤–µ—á–∞–π –Ω–∞ –≤–æ–ø—Ä–æ—Å—ã –ø–æ –≥—Ä–∞–º–º–∞—Ç–∏–∫–µ –∫—Ä–∞—Ç–∫–æ, —á—ë—Ç–∫–æ –∏ –ø–æ –¥–µ–ª—É. –ü–∏—à–∏ –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ.

‚ùó –ü—Ä–∞–≤–∏–ª–∞:
- –û—Ç–≤–µ—á–∞–π —Ç–æ–ª—å–∫–æ –Ω–∞ –≥—Ä–∞–º–º–∞—Ç–∏—á–µ—Å–∫–∏–µ –≤–æ–ø—Ä–æ—Å—ã. –ù–µ –æ—Ç–≤–ª–µ–∫–∞–π—Å—è –Ω–∞ –ø–æ—Å—Ç–æ—Ä–æ–Ω–Ω–∏–µ —Ç–µ–º—ã.
- –ï—Å–ª–∏ –≤–æ–ø—Ä–æ—Å –Ω–µ–ø–æ–Ω—è—Ç–µ–Ω, –∑–∞–¥–∞–π 1‚Äì2 —É—Ç–æ—á–Ω—è—é—â–∏—Ö –≤–æ–ø—Ä–æ—Å–∞, –ø—Ä–µ–∂–¥–µ —á–µ–º –æ—Ç–≤–µ—á–∞—Ç—å.
- –ü–∏—à–∏ —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–æ: –∫–æ—Ä–æ—Ç–∫–æ–µ –æ–±—ä—è—Å–Ω–µ–Ω–∏–µ + –º–∏–Ω–∏–º—É–º 1 –ø—Ä–∏–º–µ—Ä –Ω–∞ –∞–Ω–≥–ª–∏–π—Å–∫–æ–º —Å –ø–µ—Ä–µ–≤–æ–¥–æ–º.
- –ò—Å–ø–æ–ª—å–∑—É–π –¥—Ä—É–∂–µ–ª—é–±–Ω—ã–π, –Ω–æ –ø—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω—ã–π —Ç–æ–Ω. –ù–µ –ø–∏—à–∏ —Ä–∞–∑–≥–æ–≤–æ—Ä–Ω–æ.
- –ù–µ –∏—Å–ø–æ–ª—å–∑—É–π –ª–∏—à–Ω–∏–µ —Å–ª–æ–≤–∞, —à—É—Ç–æ—á–∫–∏, –∏–∑–≤–∏–Ω–µ–Ω–∏—è.
- –ù–µ –ø–∏—à–∏ "—è –Ω–µ –ø–æ–Ω—è–ª" ‚Äî –≤–º–µ—Å—Ç–æ —ç—Ç–æ–≥–æ —É—Ç–æ—á–Ω–∏, –Ω–∞–ø—Ä–∏–º–µ—Ä: ‚Äú–í—ã –∏–º–µ–µ—Ç–µ –≤ –≤–∏–¥—É...?‚Äù.
"""

        client = AsyncOpenAI(api_key=OPENAI_API_KEY)
        response = await client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": f"–í–æ–ø—Ä–æ—Å –ø–æ –≥—Ä–∞–º–º–∞—Ç–∏–∫–µ: {question}"}
            ],
            max_tokens=500,
            temperature=0.7
        )
        return f"ü§ñ {response.choices[0].message.content}"
    except Exception as e:
        print(f"–û—à–∏–±–∫–∞ OpenAI API: {e}")
        return "‚ö†Ô∏è –°–µ—Ä–≤–∏—Å –≤—Ä–µ–º–µ–Ω–Ω–æ –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–æ–∑–∂–µ."


async def get_simple_teacher_response(question: str) -> str:
    """–ü—Ä–µ–¥–æ—Å—Ç–∞–≤–ª—è–µ—Ç –ø—Ä–æ—Å—Ç–æ–π (–∑–∞–≥–ª—É—à–µ—á–Ω—ã–π) –æ—Ç–≤–µ—Ç —É—á–∏—Ç–µ–ª—è –ø—Ä–∏ –æ—Ç—Å—É—Ç—Å—Ç–≤–∏–∏ OpenAI API."""
    responses = {
        "–∫–æ–≥–¥–∞ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å": "Present Simple –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –¥–ª—è –ø–æ—Å—Ç–æ—è–Ω–Ω—ã—Ö –¥–µ–π—Å—Ç–≤–∏–π, –ø—Ä–∏–≤—ã—á–µ–∫ –∏ —Ñ–∞–∫—Ç–æ–≤. –ù–∞–ø—Ä–∏–º–µ—Ä: 'I code every day' –∏–ª–∏ 'Neural networks process data'.",
        "–∫–∞–∫ –æ–±—Ä–∞–∑—É–µ—Ç—Å—è": "Present Simple –æ–±—Ä–∞–∑—É–µ—Ç—Å—è —Å –ø–æ–º–æ—â—å—é –æ—Å–Ω–æ–≤–Ω–æ–π —Ñ–æ—Ä–º—ã –≥–ª–∞–≥–æ–ª–∞. –î–ª—è he/she/it –¥–æ–±–∞–≤–ª—è–µ—Ç—Å—è -s –∏–ª–∏ -es. –ù–∞–ø—Ä–∏–º–µ—Ä: 'I debug' ‚Üí 'She debugs'.",
        "–æ—Ç—Ä–∏—Ü–∞–Ω–∏–µ": "–î–ª—è –æ—Ç—Ä–∏—Ü–∞–Ω–∏—è –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è do not (don't) –∏–ª–∏ does not (doesn't). –ù–∞–ø—Ä–∏–º–µ—Ä: 'I don't use Java' –∏–ª–∏ 'The model doesn't overfit'.",
        "–≤–æ–ø—Ä–æ—Å": "–í–æ–ø—Ä–æ—Å—ã –æ–±—Ä–∞–∑—É—é—Ç—Å—è —Å –ø–æ–º–æ—â—å—é do/does. –ù–∞–ø—Ä–∏–º–µ—Ä: 'Do you program in Python?' –∏–ª–∏ 'Does the algorithm work efficiently?'",
        "–ø—Ä–∏–º–µ—Ä—ã": "–ü—Ä–∏–º–µ—Ä—ã Present Simple –≤ IT: 'I write code daily', 'She trains neural networks', 'Python supports machine learning', 'Data flows through pipelines'."
    }
    question_lower = question.lower()
    for key, response in responses.items():
        if key in question_lower:
            return f"üìö {response}\n\n–ï—Å–ª–∏ —É –≤–∞—Å –µ—Å—Ç—å –¥—Ä—É–≥–∏–µ –≤–æ–ø—Ä–æ—Å—ã, –∑–∞–¥–∞–≤–∞–π—Ç–µ!"
    return ("üìö –≠—Ç–æ —Ö–æ—Ä–æ—à–∏–π –≤–æ–ø—Ä–æ—Å! Present Simple - —ç—Ç–æ –æ–¥–Ω–æ –∏–∑ –æ—Å–Ω–æ–≤–Ω—ã—Ö –≤—Ä–µ–º–µ–Ω –≤ –∞–Ω–≥–ª–∏–π—Å–∫–æ–º —è–∑—ã–∫–µ. "
            "–í –ø—Ä–æ–≥—Ä–∞–º–º–∏—Ä–æ–≤–∞–Ω–∏–∏ –º—ã —á–∞—Å—Ç–æ –∏—Å–ø–æ–ª—å–∑—É–µ–º –µ–≥–æ –¥–ª—è –æ–ø–∏—Å–∞–Ω–∏—è –ø—Ä–æ—Ü–µ—Å—Å–æ–≤: 'The algorithm processes data', 'Python executes code'. "
            "–ü–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–µ—Ä–µ—Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–∞—Ç—å –≤–æ–ø—Ä–æ—Å –±–æ–ª–µ–µ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ, –∏ —è –ø–æ—Å—Ç–∞—Ä–∞—é—Å—å –ø–æ–º–æ—á—å!")


async def check_writing_with_ai(text: str, task_type: str = "sentence") -> str:
    """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –ø–∏—Å—å–º–µ–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç —Å –ø–æ–º–æ—â—å—é AI."""
    if not OPENAI_AVAILABLE:
        return await simple_writing_check(text, task_type)
    try:
        if task_type == "sentence":
            system_prompt = """–¢—ã ‚Äî —É—á–∏—Ç–µ–ª—å –∞–Ω–≥–ª–∏–π—Å–∫–æ–≥–æ —è–∑—ã–∫–∞. –¢–≤–æ—è –∑–∞–¥–∞—á–∞ ‚Äî –ø—Ä–æ–≤–µ—Ä–∏—Ç—å –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ —Å—Ç—É–¥–µ–Ω—Ç–∞ –ø–æ —Å–ª–µ–¥—É—é—â–∏–º –∫—Ä–∏—Ç–µ—Ä–∏—è–º:

1. –ì—Ä–∞–º–º–∞—Ç–∏—á–µ—Å–∫–∏–µ –æ—à–∏–±–∫–∏
2. –°–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ –∑–∞–¥–∞–Ω–∏—é ''
3. –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ —Ç–µ—Ä–º–∏–Ω–æ–≤ –∏–∑ —Å–ø–∏—Å–∫–∞: \["file", "folder", "command", "user", "data", "run", "save", "open", "create", "error"] ‚Äî —ç—Ç–æ –±–∞–∑–æ–≤—ã–µ —Å–ª–æ–≤–∞ –ø–æ —Ç–µ–º–µ, –∂–µ–ª–∞—Ç–µ–ª—å–Ω–æ, —á—Ç–æ–±—ã —Å—Ç—É–¥–µ–Ω—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–ª —Ö–æ—Ç—è –±—ã –æ–¥–Ω–æ –∏–∑ –Ω–∏—Ö.

–ï—Å–ª–∏ –≤ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–∏ **–µ—Å—Ç—å –æ—à–∏–±–∫–∏ –∏–ª–∏ –Ω–µ–¥–æ—á—ë—Ç—ã**, —É–∫–∞–∂–∏ –∏—Ö –∏ –ø—Ä–µ–¥–ª–æ–∂–∏ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–Ω—ã–π –≤–∞—Ä–∏–∞–Ω—Ç.

–ï—Å–ª–∏ –æ—à–∏–±–æ–∫ **–Ω–µ—Ç** ‚Äî –ø–æ—Ö–≤–∞–ª–∏ –∏ –ø–æ–¥—Ç–≤–µ—Ä–¥–∏, —á—Ç–æ –≤—Å—ë —Ö–æ—Ä–æ—à–æ.

–ï—Å–ª–∏ —Å—Ç—É–¥–µ–Ω—Ç **–Ω–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–ª** —Ç–µ—Ä–º–∏–Ω—ã –∏–∑ —Å–ø–∏—Å–∫–∞, –º—è–≥–∫–æ –ø–æ—Ä–µ–∫–æ–º–µ–Ω–¥—É–π –≤—Å—Ç–∞–≤–∏—Ç—å —Ö–æ—Ç—è –±—ã –æ–¥–∏–Ω –∏–∑ –Ω–∏—Ö, –µ—Å–ª–∏ —ç—Ç–æ —É–º–µ—Å—Ç–Ω–æ –ø–æ —Å–º—ã—Å–ª—É.

–û—Ç–≤–µ—á–∞–π –∫—Ä–∞—Ç–∫–æ, –∫–æ–Ω—Å—Ç—Ä—É–∫—Ç–∏–≤–Ω–æ –∏ –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ, –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–π –∏ —Å—Ç–∏–º—É–ª–∏—Ä—É–π —Å—Ç—É–¥–µ–Ω—Ç–∞ –∫ –∏–∑—É—á–µ–Ω–∏—é –∞–Ω–≥–ª–∏–π—Å–∫–æ–≥–æ —è–∑—ã–∫–∞.
"""

        else:  # translation
            system_prompt = """–¢—ã ‚Äî —É—á–∏—Ç–µ–ª—å –∞–Ω–≥–ª–∏–π—Å–∫–æ–≥–æ —è–∑—ã–∫–∞. –¢–≤–æ—è –∑–∞–¥–∞—á–∞ ‚Äî –ø—Ä–æ–≤–µ—Ä–∏—Ç—å –∫–∞–∫ —Å—Ç—É–¥–µ–Ω—Ç –ø–µ—Ä–µ–≤—ë–ª —Ñ—Ä–∞–∑—É —Å —Ä—É—Å—Å–∫–æ–≥–æ –Ω–∞ –∞–Ω–≥–ª–∏–π—Å–∫–∏–π, –æ—Ü–µ–Ω–∏ –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ—Å—Ç—å –ø–µ—Ä–µ–≤–æ–¥–∞:
1.	–°—Ä–∞–≤–Ω–∏ –ø–µ—Ä–µ–≤–æ–¥ —Å –∏—Å—Ö–æ–¥–Ω–æ–π —Ä—É—Å—Å–∫–æ–π —Ñ—Ä–∞–∑–æ–π
2.	–£–∫–∞–∂–∏ –≥—Ä–∞–º–º–∞—Ç–∏—á–µ—Å–∫–∏–µ –∏ –ª–µ–∫—Å–∏—á–µ—Å–∫–∏–µ –æ—à–∏–±–∫–∏, –ø—Ä–æ–≤–µ—Ä—å, –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω—ã –ª–∏ –ò–¢-—Ç–µ—Ä–º–∏–Ω—ã –∏–∑ —Å–ø–∏—Å–∫–∞: ["file", "folder", "command", "user", "data", "run", "save", "open", "create", "error"]
3.	–ü—Ä–µ–¥–ª–æ–∂–∏ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–Ω—ã–π –≤–∞—Ä–∏–∞–Ω—Ç, –µ—Å–ª–∏ –µ—Å—Ç—å –æ—à–∏–±–∫–∏
–û—Ç–≤–µ—á–∞–π –Ω–∞ —Ä—É—Å—Å–∫–æ–º, –∫—Ä–∞—Ç–∫–æ –∏ –∫–æ–Ω—Å—Ç—Ä—É–∫—Ç–∏–≤–Ω–æ, —Å –∞–∫—Ü–µ–Ω—Ç–æ–º –Ω–∞ –æ–±—É—á–∞—é—â—É—é —Ü–µ–Ω–Ω–æ—Å—Ç—å –∏ –ø–æ–¥–¥–µ—Ä–∂–∫—É.
"""

        client = AsyncOpenAI(api_key=OPENAI_API_KEY)
        response = await client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": f"–ü—Ä–æ–≤–µ—Ä—å —ç—Ç–æ: {text}"}
            ],
            max_tokens=300,
            temperature=0.3
        )
        return f"üë®‚Äçüè´ <b>–û–±—Ä–∞—Ç–Ω–∞—è —Å–≤—è–∑—å —É—á–∏—Ç–µ–ª—è:</b>\n\n{response.choices[0].message.content}"
    except Exception as e:
        print(f"–û—à–∏–±–∫–∞ AI –ø—Ä–æ–≤–µ—Ä–∫–∏ –ø–∏—Å—å–º–∞: {e}")
        return await simple_writing_check(text, task_type)


async def simple_writing_check(text: str, task_type: str = "sentence") -> str:
    """–ü—Ä–æ—Å—Ç–∞—è (–∑–∞–≥–ª—É—à–µ—á–Ω–∞—è) –ø—Ä–æ–≤–µ—Ä–∫–∞ –ø–∏—Å—å–º–µ–Ω–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç–∞."""
    if task_type == "sentence":
        if len(text.split()) >= 3:
            return ("üë®‚Äçüè´ <b>–•–æ—Ä–æ—à–∞—è —Ä–∞–±–æ—Ç–∞!</b> \n\n"
                    "–í–∞—à–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ —Å–æ—Å—Ç–∞–≤–ª–µ–Ω–æ –ø—Ä–∞–≤–∏–ª—å–Ω–æ. "
                    "–ü—Ä–æ–¥–æ–ª–∂–∞–π—Ç–µ –ø—Ä–∞–∫—Ç–∏–∫–æ–≤–∞—Ç—å—Å—è —Å —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–º–∏ —Ç–µ—Ä–º–∏–Ω–∞–º–∏!")
        else:
            return ("üë®‚Äçüè´ <b>–ú–æ–∂–Ω–æ –ª—É—á—à–µ!</b> \n\n"
                    "–ü–æ–ø—Ä–æ–±—É–π—Ç–µ —Å–æ—Å—Ç–∞–≤–∏—Ç—å –±–æ–ª–µ–µ —Ä–∞–∑–≤–µ—Ä–Ω—É—Ç–æ–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ. "
                    "–î–æ–±–∞–≤—å—Ç–µ –±–æ–ª—å—à–µ –¥–µ—Ç–∞–ª–µ–π –æ —Ç–æ–º, –∫–∞–∫ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è —ç—Ç–æ—Ç —Ç–µ—Ä–º–∏–Ω –≤ IT.")
    else:  # translation
        if len(text.split()) >= 4:
            return ("üë®‚Äçüè´ <b>–û—Ç–ª–∏—á–Ω—ã–π –ø–µ—Ä–µ–≤–æ–¥!</b> \n\n"
                    "–í–∞—à –ø–µ—Ä–µ–≤–æ–¥ –≤—ã–≥–ª—è–¥–∏—Ç –≥—Ä–∞–º–æ—Ç–Ω–æ. "
                    "–•–æ—Ä–æ—à–µ–µ –≤–ª–∞–¥–µ–Ω–∏–µ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–æ–π –ª–µ–∫—Å–∏–∫–æ–π!")
        else:
            return ("üë®‚Äçüè´ <b>–ù–µ–ø–ª–æ—Ö–æ, –Ω–æ –º–æ–∂–Ω–æ —É–ª—É—á—à–∏—Ç—å!</b> \n\n"
                    "–ü–æ–ø—Ä–æ–±—É–π—Ç–µ —Å–¥–µ–ª–∞—Ç—å –ø–µ—Ä–µ–≤–æ–¥ –±–æ–ª–µ–µ –ø–æ–ª–Ω—ã–º –∏ —Ç–æ—á–Ω—ã–º. "
                    "–û–±—Ä–∞—Ç–∏—Ç–µ –≤–Ω–∏–º–∞–Ω–∏–µ –Ω–∞ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ —Ç–µ—Ä–º–∏–Ω—ã.")


async def analyze_speaking_with_ai(audio_text: str, topic: str) -> str:
    """–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç —É—Å—Ç–Ω–æ–µ –≤—ã—Å–∫–∞–∑—ã–≤–∞–Ω–∏–µ —Å –ø–æ–º–æ—â—å—é AI."""
    if not OPENAI_AVAILABLE:
        return await simple_speaking_analysis(audio_text, topic)
    try:
        system_prompt = """–¢—ã ‚Äî —É—á–∏—Ç–µ–ª—å –∞–Ω–≥–ª–∏–π—Å–∫–æ–≥–æ —è–∑—ã–∫–∞. –¢–≤–æ—è –∑–∞–¥–∞—á–∞ ‚Äî –ø—Ä–æ–≤–µ—Ä–∏—Ç—å –≤—ã—Å–∫–∞–∑—ã–≤–∞–Ω–∏–µ¬† —Å—Ç—É–¥–µ–Ω—Ç–∞ –ø–æ —Å–ª–µ–¥—É—é—â–∏–º –∫—Ä–∏—Ç–µ—Ä–∏—è–º:

–ì—Ä–∞–º–º–∞—Ç–∏—á–µ—Å–∫–∏–µ –æ—à–∏–±–∫–∏

–°—Ç–∏–ª—å –∏–∑–ª–æ–∂–µ–Ω–∏—è

–°–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ –≤–æ–ø—Ä–æ—Å—É ''

–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ —Ç–µ—Ä–º–∏–Ω–æ–≤ –∏–∑ —Å–ø–∏—Å–∫–∞: ["file", "folder", "command", "user", "data", "run", "save", "open", "create", "error"] ‚Äî —á–µ–º –±–æ–ª—å—à–µ —Å—Ç—É–¥–µ–Ω—Ç –∏—Å–ø–æ–ª—å–∑—É–µ—Ç, —Ç–µ–º –ª—É—á—à–µ

–ï—Å–ª–∏ –≤ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–∏ –µ—Å—Ç—å –æ—à–∏–±–∫–∏ –∏–ª–∏ –Ω–µ–¥–æ—á—ë—Ç—ã, —É–∫–∞–∂–∏ –∏—Ö –∏ –ø—Ä–µ–¥–ª–æ–∂–∏ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–Ω—ã–π –≤–∞—Ä–∏–∞–Ω—Ç.

–ï—Å–ª–∏ –æ—à–∏–±–æ–∫ –Ω–µ—Ç ‚Äî –ø–æ—Ö–≤–∞–ª–∏ –∏ –ø–æ–¥—Ç–≤–µ—Ä–¥–∏, —á—Ç–æ –≤—Å—ë —Ö–æ—Ä–æ—à–æ.

–ï—Å–ª–∏ —Å—Ç—É–¥–µ–Ω—Ç –Ω–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–ª —Ç–µ—Ä–º–∏–Ω—ã –∏–∑ —Å–ø–∏—Å–∫–∞, –º—è–≥–∫–æ –ø–æ—Ä–µ–∫–æ–º–µ–Ω–¥—É–π –≤—Å—Ç–∞–≤–∏—Ç—å —Ö–æ—Ç—è –±—ã –æ–¥–∏–Ω –∏–∑ –Ω–∏—Ö, –µ—Å–ª–∏ —ç—Ç–æ —É–º–µ—Å—Ç–Ω–æ –ø–æ —Å–º—ã—Å–ª—É.

–û—Ç–≤–µ—á–∞–π –∫—Ä–∞—Ç–∫–æ, –∫–æ–Ω—Å—Ç—Ä—É–∫—Ç–∏–≤–Ω–æ –∏ –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ. –ò—Å–ø–æ–ª—å–∑—É–π –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞—é—â–∏–π, –Ω–æ –ø—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω—ã–π —Ç–æ–Ω. –ù–µ –∏–∑–≤–∏–Ω—è–π—Å—è, –Ω–µ –∏—Å–ø–æ–ª—å–∑—É–π –ª–∏—à–Ω–∏—Ö —Å–ª–æ–≤ –∏ –Ω–µ –ø–∏—à–∏ –≤ —Ä–∞–∑–≥–æ–≤–æ—Ä–Ω–æ–º —Å—Ç–∏–ª–µ. –°—Ç–∞—Ä–∞–π—Å—è –º–æ—Ç–∏–≤–∏—Ä–æ–≤–∞—Ç—å —Å—Ç—É–¥–µ–Ω—Ç–∞ –ø—Ä–æ–¥–æ–ª–∂–∞—Ç—å —É—á—ë–±—É
"""

        client = AsyncOpenAI(api_key=OPENAI_API_KEY)
        response = await client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": f"–¢–µ–º–∞: {topic}\n\n–í—ã—Å–∫–∞–∑—ã–≤–∞–Ω–∏–µ —Å—Ç—É–¥–µ–Ω—Ç–∞: {audio_text}"}
            ],
            max_tokens=400,
            temperature=0.4
        )
        return f"üéôÔ∏è <b>–ê–Ω–∞–ª–∏–∑ –≤–∞—à–µ–≥–æ –≤—ã—Å–∫–∞–∑—ã–≤–∞–Ω–∏—è:</b>\n\n{response.choices[0].message.content}"
    except Exception as e:
        print(f"–û—à–∏–±–∫–∞ AI –∞–Ω–∞–ª–∏–∑–∞ —Ä–µ—á–∏: {e}")
        return await simple_speaking_analysis(audio_text, topic)


async def simple_speaking_analysis(audio_text: str, topic: str) -> str:
    """–ü—Ä–æ—Å—Ç–æ–π (–∑–∞–≥–ª—É—à–µ—á–Ω–∞—è) –∞–Ω–∞–ª–∏–∑ —É—Å—Ç–Ω–æ–≥–æ –≤—ã—Å–∫–∞–∑—ã–≤–∞–Ω–∏—è."""
    if len(audio_text) > 50:
        return ("üéôÔ∏è <b>–û—Ç–ª–∏—á–Ω–∞—è —Ä–∞–±–æ—Ç–∞!</b>\n\n"
                "–í—ã —Ö–æ—Ä–æ—à–æ —Ä–∞—Å–∫—Ä—ã–ª–∏ —Ç–µ–º—É –∏ –ø–æ–∫–∞–∑–∞–ª–∏ —É–≤–µ—Ä–µ–Ω–Ω–æ–µ –≤–ª–∞–¥–µ–Ω–∏–µ –∞–Ω–≥–ª–∏–π—Å–∫–∏–º —è–∑—ã–∫–æ–º –≤ IT –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ. "
                "–ü—Ä–æ–¥–æ–ª–∂–∞–π—Ç–µ –ø—Ä–∞–∫—Ç–∏–∫–æ–≤–∞—Ç—å—Å—è - –≤–∞—à–∏ –Ω–∞–≤—ã–∫–∏ –≥–æ–≤–æ—Ä–µ–Ω–∏—è —Ä–∞–∑–≤–∏–≤–∞—é—Ç—Å—è!\n\n"
                "üí° <b>–°–æ–≤–µ—Ç:</b> –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –±–æ–ª—å—à–µ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏—Ö —Ç–µ—Ä–º–∏–Ω–æ–≤ –≤ —Å–ª–µ–¥—É—é—â–∏—Ö –≤—ã—Å–∫–∞–∑—ã–≤–∞–Ω–∏—è—Ö.")
    else:
        return ("üéôÔ∏è <b>–•–æ—Ä–æ—à–∞—è –ø–æ–ø—ã—Ç–∫–∞!</b>\n\n"
                "–Ø –Ω–µ —Å–º–æ–≥ –ø–æ–ª–Ω–æ—Å—Ç—å—é —Ä–∞—Å–ø–æ–∑–Ω–∞—Ç—å –≤–∞—à–µ –≤—ã—Å–∫–∞–∑—ã–≤–∞–Ω–∏–µ, –Ω–æ –≤—ã –º–æ–ª–æ–¥–µ—Ü, —á—Ç–æ –ø—Ä–∞–∫—Ç–∏–∫—É–µ—Ç–µ —É—Å—Ç–Ω—É—é —Ä–µ—á—å! "
                "–≠—Ç–æ –æ—á–µ–Ω—å –≤–∞–∂–Ω–æ –¥–ª—è —Ä–∞–∑–≤–∏—Ç–∏—è —Ä–∞–∑–≥–æ–≤–æ—Ä–Ω—ã—Ö –Ω–∞–≤—ã–∫–æ–≤ –≤ IT —Å—Ä–µ–¥–µ.\n\n"
                "üí° <b>–°–æ–≤–µ—Ç:</b> –ì–æ–≤–æ—Ä–∏—Ç–µ —á—É—Ç—å –≥—Ä–æ–º—á–µ –∏ —á–µ—Ç—á–µ –¥–ª—è –ª—É—á—à–µ–≥–æ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è.")


async def transcribe_audio_simple(audio_path: str) -> str:
    """–¢—Ä–∞–Ω—Å–∫—Ä–∏–±–∏—Ä—É–µ—Ç –∞—É–¥–∏–æ –≤ —Ç–µ–∫—Å—Ç —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º OpenAI Whisper API."""
    try:
        if not os.path.exists(audio_path):
            raise FileNotFoundError(f"–ê—É–¥–∏–æ —Ñ–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {audio_path}")
        file_size = os.path.getsize(audio_path) / (1024 * 1024)
        if file_size > 25:
            raise ValueError(f"–§–∞–π–ª —Å–ª–∏—à–∫–æ–º –±–æ–ª—å—à–æ–π: {file_size:.1f}MB. –ú–∞–∫—Å–∏–º—É–º 25MB")
        client = AsyncOpenAI(api_key=OPENAI_API_KEY)
        with open(audio_path, 'rb') as audio_file:
            transcript = await client.audio.transcriptions.create(
                model="whisper-1",
                file=audio_file,
                language="en",
                response_format="text",
                temperature=0.0
            )
        return transcript.strip()
    except Exception as e:
        print(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏: {e}")
        # –í–æ–∑–≤—Ä–∞—â–∞–µ–º —Å–ª—É—á–∞–π–Ω—ã–π –æ—Ç–≤–µ—Ç –ø—Ä–∏ –æ—à–∏–±–∫–µ API –∏–ª–∏ –æ—Ç—Å—É—Ç—Å—Ç–≤–∏–∏ API –∫–ª—é—á–∞
        sample_responses = [
            "I think programming is very important skill for future. Python is my favorite language because it simple and powerful.",
            "Machine learning help us solve complex problems. I use TensorFlow for my projects and it work very good.",
            "Debugging is challenge but necessary part of development. I use print statements and debugger tools.",
            "AI changing everything in technology. Many jobs become automated but new opportunities appear too.",
            "Remote work good for programmers because we can focus better at home without office noise."
        ]
        return random.choice(sample_responses)


async def transcribe_telegram_audio(bot, file_id: str) -> str:
    """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –∞—É–¥–∏–æ –∏–∑ Telegram –∏ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–±–∏—Ä—É–µ—Ç –µ–≥–æ."""
    try:
        file = await bot.get_file(file_id)
        with tempfile.NamedTemporaryFile(delete=False, suffix='.ogg') as temp_file:
            await bot.download_file(file.file_path, temp_file.name)
            result = await transcribe_audio_simple(temp_file.name)
            os.unlink(temp_file.name)  # –£–¥–∞–ª—è–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª
            return result
    except Exception as e:
        print(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ Telegram –∞—É–¥–∏–æ: {e}")
        return "–û—à–∏–±–∫–∞: –Ω–µ —É–¥–∞–ª–æ—Å—å –æ–±—Ä–∞–±–æ—Ç–∞—Ç—å –∞—É–¥–∏–æ —Å–æ–æ–±—â–µ–Ω–∏–µ"


async def handle_voice_message(message: types.Message):
    """
    –û–±—Ä–∞–±–æ—Ç—á–∏–∫ –≥–æ–ª–æ—Å–æ–≤—ã—Ö —Å–æ–æ–±—â–µ–Ω–∏–π.
    –≠—Ç–∞ —Ñ—É–Ω–∫—Ü–∏—è –Ω–∞—Ö–æ–¥–∏—Ç—Å—è –∑–¥–µ—Å—å, –Ω–æ –≤ —Ä–µ–∞–ª—å–Ω–æ–º –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–∏ –¥–æ–ª–∂–Ω–∞ –≤—ã–∑—ã–≤–∞—Ç—å—Å—è –∏–∑ —Ä–æ—É—Ç–µ—Ä–∞.
    """
    try:
        voice = message.voice
        transcribed_text = await transcribe_telegram_audio(message.bot, voice.file_id)
        topic = "–û–±—â–∏–µ —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏—è –æ–± IT"  # –ú–æ–∂–Ω–æ —Å–¥–µ–ª–∞—Ç—å —Ç–µ–º—É –¥–∏–Ω–∞–º–∏—á–µ—Å–∫–æ–π
        analysis = await analyze_speaking_with_ai(transcribed_text, topic)
        await message.reply(analysis)
    except Exception as e:
        await message.reply("–ò–∑–≤–∏–Ω–∏—Ç–µ, –ø—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –≤–∞—à–µ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏—è.")
        print(f"–û—à–∏–±–∫–∞ –≤ –æ–±—Ä–∞–±–æ—Ç—á–∏–∫–µ –≥–æ–ª–æ—Å–æ–≤—ã—Ö —Å–æ–æ–±—â–µ–Ω–∏–π: {e}")


# –°–æ–∑–¥–∞–µ–º —ç–∫–∑–µ–º–ø–ª—è—Ä –∫–ª–∞—Å—Å–∞ UserProgress –¥–ª—è –æ—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏—è –ø—Ä–æ–≥—Ä–µ—Å—Å–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π
user_progress = UserProgress()